{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "from music21 import converter, instrument, note, chord\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_offset = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midis(file):\n",
    "    notes = []\n",
    "    offsets = []\n",
    "    midi = converter.parse(file)\n",
    "    notes_to_parse = midi.flat.notes\n",
    "    for i in range(len(notes_to_parse)):\n",
    "        if i != len(notes_to_parse) - 1:\n",
    "            offsets.append(notes_to_parse[i+1].offset-notes_to_parse[i].offset)\n",
    "        else:\n",
    "            offsets.append(default_offset)\n",
    "        if isinstance(notes_to_parse[i], note.Note):\n",
    "            notes.append(str(notes_to_parse[i].pitch))\n",
    "        elif isinstance(notes_to_parse[i], chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in notes_to_parse[i].normalOrder))\n",
    "    return notes,offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = [file for file in glob.glob(\"midis/*.mid\")]\n",
    "random.shuffle(midi_files)\n",
    "\n",
    "final_notes,final_offsets = map(list,zip(*[read_midis(file) for file in midi_files]))\n",
    "\n",
    "all_notes = []\n",
    "for note_array in final_notes:\n",
    "    for elem in note_array:\n",
    "        all_notes.append(elem)\n",
    "all_notes = np.array(all_notes)\n",
    "\n",
    "all_offsets = []\n",
    "for offset_array in final_offsets:\n",
    "    for indivOff in offset_array:\n",
    "        all_offsets.append(float(indivOff))\n",
    "all_offsets = np.around(np.array(all_offsets),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_offset_pairs = list(zip(all_notes, all_offsets))\n",
    "n_vocab = len(set(note_offset_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairings = sorted(set(item for item in note_offset_pairs))\n",
    "sequence_length = 60\n",
    "pair_to_int = dict((pair, number) for number, pair in enumerate(pairings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_in = []\n",
    "network_out = []\n",
    "for i in range(0, len(all_notes) - sequence_length):\n",
    "    seq_in = note_offset_pairs[i:i+sequence_length]\n",
    "    seq_out = note_offset_pairs[i + sequence_length]\n",
    "    network_in.append([pair_to_int[elem] for elem in seq_in])\n",
    "    network_out.append(pair_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(network_in)\n",
    "network_in_array = np.reshape(network_in, (n_patterns, sequence_length,1)) / float(n_vocab)\n",
    "network_out = keras.utils.to_categorical(network_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dropout(0.8))\n",
    "model.add(keras.layers.LSTM(256, input_shape = (network_in_array.shape[1], network_in_array.shape[2]), return_sequences = True))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.LSTM(128))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(n_vocab, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "195/195 [==============================] - 6s 12ms/step - loss: 4.8687\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.5692\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.5813\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.5135\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.3302\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.2564\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.2059\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 2s 13ms/step - loss: 4.1970\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.1801\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.1201\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.0868\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 4.0713\n",
      "Epoch 13/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.9963\n",
      "Epoch 14/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.9922\n",
      "Epoch 15/100\n",
      "195/195 [==============================] - 3s 18ms/step - loss: 3.9518\n",
      "Epoch 16/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.9256\n",
      "Epoch 17/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.8122\n",
      "Epoch 18/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.7746\n",
      "Epoch 19/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.7455\n",
      "Epoch 20/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.6844\n",
      "Epoch 21/100\n",
      "195/195 [==============================] - 4s 18ms/step - loss: 3.6374\n",
      "Epoch 22/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.6449\n",
      "Epoch 23/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.5432\n",
      "Epoch 24/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.5313\n",
      "Epoch 25/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.4691: 0s \n",
      "Epoch 26/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.4756\n",
      "Epoch 27/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.4032\n",
      "Epoch 28/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.3631\n",
      "Epoch 29/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.3035\n",
      "Epoch 30/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.2949\n",
      "Epoch 31/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.2779\n",
      "Epoch 32/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.2134\n",
      "Epoch 33/100\n",
      "195/195 [==============================] - 4s 19ms/step - loss: 3.2053\n",
      "Epoch 34/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.1455\n",
      "Epoch 35/100\n",
      "195/195 [==============================] - 3s 14ms/step - loss: 3.1366\n",
      "Epoch 36/100\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 3.0767\n",
      "Epoch 37/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.0827\n",
      "Epoch 38/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.9966\n",
      "Epoch 39/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.0050\n",
      "Epoch 40/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.9682\n",
      "Epoch 41/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 3.0041\n",
      "Epoch 42/100\n",
      "195/195 [==============================] - 4s 22ms/step - loss: 2.9100\n",
      "Epoch 43/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.9498\n",
      "Epoch 44/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.9060\n",
      "Epoch 45/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.8880\n",
      "Epoch 46/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.8633\n",
      "Epoch 47/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.8736\n",
      "Epoch 48/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.8514\n",
      "Epoch 49/100\n",
      "195/195 [==============================] - 4s 21ms/step - loss: 2.8138\n",
      "Epoch 50/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.8181\n",
      "Epoch 51/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7860\n",
      "Epoch 52/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7424\n",
      "Epoch 53/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7876\n",
      "Epoch 54/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7464\n",
      "Epoch 55/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7111\n",
      "Epoch 56/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7082\n",
      "Epoch 57/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7076\n",
      "Epoch 58/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7109\n",
      "Epoch 59/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7077\n",
      "Epoch 60/100\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 2.6442\n",
      "Epoch 61/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.6810\n",
      "Epoch 62/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.7081\n",
      "Epoch 63/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.6419\n",
      "Epoch 64/100\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 2.6931\n",
      "Epoch 65/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.6418\n",
      "Epoch 66/100\n",
      "195/195 [==============================] - 4s 18ms/step - loss: 2.5954\n",
      "Epoch 67/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.6284\n",
      "Epoch 68/100\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 2.5845\n",
      "Epoch 69/100\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 2.5529\n",
      "Epoch 70/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5719\n",
      "Epoch 71/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5654\n",
      "Epoch 72/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5401\n",
      "Epoch 73/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5544\n",
      "Epoch 74/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5305\n",
      "Epoch 75/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5477\n",
      "Epoch 76/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5382\n",
      "Epoch 77/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5501\n",
      "Epoch 78/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5776\n",
      "Epoch 79/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5336\n",
      "Epoch 80/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.5164\n",
      "Epoch 81/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4908\n",
      "Epoch 82/100\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 2.4818\n",
      "Epoch 83/100\n",
      "195/195 [==============================] - 2s 13ms/step - loss: 2.5061\n",
      "Epoch 84/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4741\n",
      "Epoch 85/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4671\n",
      "Epoch 86/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4236\n",
      "Epoch 87/100\n",
      "195/195 [==============================] - 2s 13ms/step - loss: 2.4796\n",
      "Epoch 88/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4314: 0s - los\n",
      "Epoch 89/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4848\n",
      "Epoch 90/100\n",
      "195/195 [==============================] - 4s 19ms/step - loss: 2.4387\n",
      "Epoch 91/100\n",
      "195/195 [==============================] - 3s 14ms/step - loss: 2.4362\n",
      "Epoch 92/100\n",
      "195/195 [==============================] - 4s 18ms/step - loss: 2.4016\n",
      "Epoch 93/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4438\n",
      "Epoch 94/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4238\n",
      "Epoch 95/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4292\n",
      "Epoch 96/100\n",
      "195/195 [==============================] - 2s 13ms/step - loss: 2.3991\n",
      "Epoch 97/100\n",
      "195/195 [==============================] - 2s 13ms/step - loss: 2.4106\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4129\n",
      "Epoch 99/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.4123\n",
      "Epoch 100/100\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 2.3433\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "history = model.fit(network_in_array, network_out, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(network_in)-1)\n",
    "int_to_pair = dict((number,pair) for number, pair in enumerate(pairings))\n",
    "\n",
    "pattern = network_in[start]\n",
    "pred_out = []\n",
    "\n",
    "for note_index in range(500):\n",
    "    pred_in = np.reshape(pattern, (1, len(pattern),1)) / float(n_vocab)\n",
    "    prediction = model.predict(pred_in, verbose = 0)\n",
    "    \n",
    "    index = np.random.choice(np.arange(n_vocab), p=prediction.reshape(n_vocab))\n",
    "    result = int_to_pair[index]\n",
    "    pred_out.append(result)\n",
    "    \n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "for pattern in pred_out:\n",
    "    if ('.' in pattern[0]) or pattern[0].isdigit():\n",
    "        notes_in_chord = pattern[0].split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.ElectricGuitar()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    else:\n",
    "        new_note = note.Note(pattern[0])\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.ElectricGuitar()\n",
    "        output_notes.append(new_note)\n",
    "    offset += pattern[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_out.mid'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_stream = music21.stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp = 'test_out.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
